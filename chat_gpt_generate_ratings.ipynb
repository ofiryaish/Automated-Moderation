{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "1jeaOmJnqqRL"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "client = openai.OpenAI(api_key='YOUR API TOKEN')\n",
        "\n",
        "def get_chatgpt_response(prompt):\n",
        "    \"\"\"Gets a response from ChatGPT using the OpenAI API\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",  # The ChatGPT model\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,  # Control the creativity of the response\n",
        "        max_tokens=200  # Limit the length of the response\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>prompt</th>\n",
              "      <th>label</th>\n",
              "      <th>base_model_moderation</th>\n",
              "      <th>fine_tuned_model_moderation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Assume you are a forum moderator. Please respo...</td>\n",
              "      <td>SodaPalooza, it's important to remember that t...</td>\n",
              "      <td>SodaPalooza, I understand your perspective, b...</td>\n",
              "      <td>\\nSodaPalooza, it's important for you to engag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Assume you are a forum moderator. Please respo...</td>\n",
              "      <td>TS1307, while your points are well-argued, it'...</td>\n",
              "      <td>BlckJck103: I understand your perspective and...</td>\n",
              "      <td>\\nTS1307, please remember to keep the conversa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Assume you are a forum moderator. Please respo...</td>\n",
              "      <td>Blindweaponsfumbler, please remember to keep t...</td>\n",
              "      <td>Blindweaponsfumbler, I understand that you ha...</td>\n",
              "      <td>\\nBlindweaponsfumbler, please try to focus on ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Assume you are a forum moderator. Please respo...</td>\n",
              "      <td>Celtabria, it's important to consider the impa...</td>\n",
              "      <td>I understand your perspective, Celtabria. How...</td>\n",
              "      <td>\\nCeltabria, please remember to keep the conve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Assume you are a forum moderator. Please respo...</td>\n",
              "      <td>arden13, it seems like you are providing a tho...</td>\n",
              "      <td>arden13, I understand that this is a complex ...</td>\n",
              "      <td>arden13, please remember to keep the conversat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>342</td>\n",
              "      <td>Assume you are a forum moderator. Please respo...</td>\n",
              "      <td>Pleberal, please remember to keep the conversa...</td>\n",
              "      <td>I agree with GaslightProphet that the assumpt...</td>\n",
              "      <td>\\nPleberal, please remember to keep the conver...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>343</td>\n",
              "      <td>Assume you are a forum moderator. Please respo...</td>\n",
              "      <td>beend1p, thank you for providing information a...</td>\n",
              "      <td>Trumpologist, it's important to keep the conv...</td>\n",
              "      <td>\\nbeend1p, your points have been interesting a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>344</td>\n",
              "      <td>Assume you are a forum moderator. Please respo...</td>\n",
              "      <td>z3r0shade, it's important to remember that whi...</td>\n",
              "      <td>z3r0shade, I understand that you have strong ...</td>\n",
              "      <td>\\nz3r0shade, it seems like you're raising some...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>345</td>\n",
              "      <td>Assume you are a forum moderator. Please respo...</td>\n",
              "      <td>BeansforHomerclese, it's important to remember...</td>\n",
              "      <td>BeansforHomerclese, I understand your perspec...</td>\n",
              "      <td>\\nBeansforHomerclese, it's important to rememb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>346</td>\n",
              "      <td>Assume you are a forum moderator. Please respo...</td>\n",
              "      <td>GalacticCow, it's important to remember that w...</td>\n",
              "      <td>GalacticCow, it's important to remember that ...</td>\n",
              "      <td>\\nGalacticCow, please remember to keep the con...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>347 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Unnamed: 0                                             prompt  \\\n",
              "0             0  Assume you are a forum moderator. Please respo...   \n",
              "1             1  Assume you are a forum moderator. Please respo...   \n",
              "2             2  Assume you are a forum moderator. Please respo...   \n",
              "3             3  Assume you are a forum moderator. Please respo...   \n",
              "4             4  Assume you are a forum moderator. Please respo...   \n",
              "..          ...                                                ...   \n",
              "342         342  Assume you are a forum moderator. Please respo...   \n",
              "343         343  Assume you are a forum moderator. Please respo...   \n",
              "344         344  Assume you are a forum moderator. Please respo...   \n",
              "345         345  Assume you are a forum moderator. Please respo...   \n",
              "346         346  Assume you are a forum moderator. Please respo...   \n",
              "\n",
              "                                                 label  \\\n",
              "0    SodaPalooza, it's important to remember that t...   \n",
              "1    TS1307, while your points are well-argued, it'...   \n",
              "2    Blindweaponsfumbler, please remember to keep t...   \n",
              "3    Celtabria, it's important to consider the impa...   \n",
              "4    arden13, it seems like you are providing a tho...   \n",
              "..                                                 ...   \n",
              "342  Pleberal, please remember to keep the conversa...   \n",
              "343  beend1p, thank you for providing information a...   \n",
              "344  z3r0shade, it's important to remember that whi...   \n",
              "345  BeansforHomerclese, it's important to remember...   \n",
              "346  GalacticCow, it's important to remember that w...   \n",
              "\n",
              "                                 base_model_moderation  \\\n",
              "0     SodaPalooza, I understand your perspective, b...   \n",
              "1     BlckJck103: I understand your perspective and...   \n",
              "2     Blindweaponsfumbler, I understand that you ha...   \n",
              "3     I understand your perspective, Celtabria. How...   \n",
              "4     arden13, I understand that this is a complex ...   \n",
              "..                                                 ...   \n",
              "342   I agree with GaslightProphet that the assumpt...   \n",
              "343   Trumpologist, it's important to keep the conv...   \n",
              "344   z3r0shade, I understand that you have strong ...   \n",
              "345   BeansforHomerclese, I understand your perspec...   \n",
              "346   GalacticCow, it's important to remember that ...   \n",
              "\n",
              "                           fine_tuned_model_moderation  \n",
              "0    \\nSodaPalooza, it's important for you to engag...  \n",
              "1    \\nTS1307, please remember to keep the conversa...  \n",
              "2    \\nBlindweaponsfumbler, please try to focus on ...  \n",
              "3    \\nCeltabria, please remember to keep the conve...  \n",
              "4    arden13, please remember to keep the conversat...  \n",
              "..                                                 ...  \n",
              "342  \\nPleberal, please remember to keep the conver...  \n",
              "343  \\nbeend1p, your points have been interesting a...  \n",
              "344  \\nz3r0shade, it seems like you're raising some...  \n",
              "345  \\nBeansforHomerclese, it's important to rememb...  \n",
              "346  \\nGalacticCow, please remember to keep the con...  \n",
              "\n",
              "[347 rows x 5 columns]"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "generated_modertion_df = pd.read_csv(\"test_with_fine_tuned_moderations.csv\")\n",
        "generated_modertion_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "generated_modertion_df = generated_modertion_df[generated_modertion_df[\"base_model_moderation\"] != \"prompt too long...\"]\n",
        "generated_modertion_df = generated_modertion_df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gpt_rate_prompt(converstion, autor, moderation_1, moderation_2, rating_scheme=1):\n",
        "    if rating_scheme == 1:\n",
        "        return gpt_rate_prompt_1(converstion, autor, moderation_1, moderation_2)\n",
        "    elif rating_scheme == 2:\n",
        "        return gpt_rate_prompt_2(converstion, autor, moderation_1, moderation_2)\n",
        "\n",
        "\n",
        "def gpt_rate_prompt_1(converstion, autor, moderation_1, moderation_2):\n",
        "    return f\"\"\"This is a conversation from the CMV forum:\n",
        "\n",
        "{converstion}\n",
        "\n",
        "{autor} got moderation messages:\n",
        "\n",
        "The first moderation message:\n",
        "---Message starts here---\n",
        "{moderation_1}\n",
        "---Message ends here---\n",
        "\n",
        "The second moderation message:\n",
        "---Message starts here---\n",
        "{moderation_2}\n",
        "---Message ends here---\n",
        "\n",
        "Please rate the messages from 1 to 5, according to this:\n",
        "1 indicates the message seems highly machine-generated and inappropriate.\n",
        "3 indicates a neutral perception.\n",
        "5 indicates the message seems highly human-like and appropriate.\n",
        "\n",
        "Your respone should be in this format and only in this format:\n",
        "\n",
        "Message 1 rating: <number>\n",
        "Reason: <your reason for the rate>\n",
        "\n",
        "Message 2 rating: <number>\n",
        "Reason: <your reason for the rate>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def gpt_rate_prompt_2(converstion, autor, moderation_1, moderation_2):\n",
        "    return f\"\"\"This is a conversation from the CMV forum:\n",
        "\n",
        "{converstion}\n",
        "\n",
        "{autor} got moderation messages:\n",
        "\n",
        "The first moderation message:\n",
        "---Message starts here---\n",
        "{moderation_1}\n",
        "---Message ends here---\n",
        "\n",
        "The second moderation message:\n",
        "---Message starts here---\n",
        "{moderation_2}\n",
        "---Message ends here---\n",
        "\n",
        "\n",
        "Please rate the messages from 0 to 4, according to this:\n",
        "1 point for human-like and appropriate.\n",
        "1 point for addressing the user that replaying to.\n",
        "1 point for addressing the issue with the last comment of the user you are replying to.\n",
        "1 point for a concise/short yet informative moderation message.\n",
        "\n",
        "Your response should be in this format and only in this format:\n",
        "\n",
        "Message 1 rating: <number>\n",
        "Reason: <your reason for the rate>\n",
        "\n",
        "Message 2 rating: <number>\n",
        "Reason: <your reason for the rate>\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "rating scheme 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "base_model_moderation_rates = []\n",
        "fine_tuned_model_moderation_rates = []\n",
        "chat_gpt_response = []\n",
        "\n",
        "for i in range(len(generated_modertion_df)):\n",
        "    # extract the converstion\n",
        "    pattern = r'^Assume you are a forum moderator. Please respond to .*, as his response might require a moderation note.\\s+'\n",
        "    conversion = re.sub(pattern, '', generated_modertion_df[\"prompt\"][i])\n",
        "\n",
        "    # Find the match\n",
        "    match_pos = conversion.find(\"Do not try to counter \")\n",
        "    conversion = conversion[:match_pos]\n",
        "    conversion = conversion.strip(\"\\n\")\n",
        "\n",
        "    # get the user that need moderation node\n",
        "    author = conversion.split(\"\\n\")[-1].split(\":\")[0]\n",
        "    moderation_1 = generated_modertion_df[\"base_model_moderation\"][i]\n",
        "    moderation_2 = generated_modertion_df[\"fine_tuned_model_moderation\"][i]\n",
        "\n",
        "    try:\n",
        "        gpt_rates = get_chatgpt_response(gpt_rate_prompt(conversion, author, moderation_1, moderation_2, rating_scheme=1))\n",
        "        chat_gpt_response.append(gpt_rates)\n",
        "        rate_1 = float(gpt_rates[len(\"Message 1 rating: \"): gpt_rates.find(\"\\n\")])\n",
        "        rate_2_str = gpt_rates[gpt_rates.find(\"Message 2 rating: \") + len(\"Message 2 rating: \"):]\n",
        "        rate_2 = float(rate_2_str[:rate_2_str.find(\"\\n\")])\n",
        "\n",
        "        base_model_moderation_rates.append(rate_1)\n",
        "        fine_tuned_model_moderation_rates.append(rate_2)\n",
        "    except:\n",
        "        print(i, \"is two long for chatGPT\")\n",
        "        chat_gpt_response.append(\"prompt too long...\")\n",
        "        base_model_moderation_rates.append(np.nan)\n",
        "        fine_tuned_model_moderation_rates.append(np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chat_gpt_scores_df = pd.DataFrame(data={\"chat_gpt_response\": chat_gpt_response, \"base_model_moderation_rates\": base_model_moderation_rates, \"fine_tuned_model_moderation_rates\": fine_tuned_model_moderation_rates})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "chat_gpt_scores_df.to_csv(\"test_fine_tune_chatGPT_rating_1.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "rating scheme 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "base_model_moderation_rates = []\n",
        "fine_tuned_model_moderation_rates = []\n",
        "chat_gpt_response = []\n",
        "\n",
        "for i in range(len(generated_modertion_df)):\n",
        "    # extract the converstion\n",
        "    pattern = r'^Assume you are a forum moderator. Please respond to .*, as his response might require a moderation note.\\s+'\n",
        "    conversion = re.sub(pattern, '', generated_modertion_df[\"prompt\"][i])\n",
        "\n",
        "    # Find the match\n",
        "    match_pos = conversion.find(\"Do not try to counter \")\n",
        "    conversion = conversion[:match_pos]\n",
        "    conversion = conversion.strip(\"\\n\")\n",
        "\n",
        "    # get the user that need moderation node\n",
        "    author = conversion.split(\"\\n\")[-1].split(\":\")[0]\n",
        "    moderation_1 = generated_modertion_df[\"base_model_moderation\"][i]\n",
        "    moderation_2 = generated_modertion_df[\"fine_tuned_model_moderation\"][i]\n",
        "    if i % 50 == 0:\n",
        "        print(\"check prompt:\")\n",
        "        print(gpt_rate_prompt(conversion, author, moderation_1, moderation_2))\n",
        "        print(\"*\" * 50)\n",
        "    try:\n",
        "        gpt_rates = get_chatgpt_response(gpt_rate_prompt(conversion, author, moderation_1, moderation_2))\n",
        "        chat_gpt_response.append(gpt_rates)\n",
        "        rate_1 = float(gpt_rates[len(\"Message 1 rating: \"): gpt_rates.find(\"\\n\")])\n",
        "        rate_2_str = gpt_rates[gpt_rates.find(\"Message 2 rating: \") + len(\"Message 2 rating: \"):]\n",
        "        rate_2 = float(rate_2_str[:rate_2_str.find(\"\\n\")])\n",
        "\n",
        "        base_model_moderation_rates.append(rate_1)\n",
        "        fine_tuned_model_moderation_rates.append(rate_2)\n",
        "    except:\n",
        "        print(i, \"is two long for chatGPT\")\n",
        "        chat_gpt_response.append(\"prompt too long...\")\n",
        "        base_model_moderation_rates.append(np.nan)\n",
        "        fine_tuned_model_moderation_rates.append(np.nan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chat_gpt_scores_df = pd.DataFrame(data={\"chat_gpt_response\": chat_gpt_response, \"base_model_moderation_rates\": base_model_moderation_rates, \"fine_tuned_model_moderation_rates\": fine_tuned_model_moderation_rates})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "chat_gpt_scores_df.to_csv(\"test_fine_tune_chatGPT_rating_2.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
