{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.14.287, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "from accelerate import FullyShardedDataParallelPlugin, Accelerator\n",
    "from torch.distributed.fsdp.fully_sharded_data_parallel import FullOptimStateDictConfig, FullStateDictConfig\n",
    "\n",
    "fsdp_plugin = FullyShardedDataParallelPlugin(\n",
    "    state_dict_config=FullStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    "    optim_state_dict_config=FullOptimStateDictConfig(offload_to_cpu=True, rank0_only=False),\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(fsdp_plugin=fsdp_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016495704650878906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23fea7dd7bcb404595c115c96372aabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tables\n",
    "conversation_df = pd.read_csv(\"annotated_trees_101.csv\")\n",
    "conversation_df = conversation_df.rename({'Unnamed: 0': \"index\"}, axis=1)\n",
    "df_only_bad_tone = pd.read_csv(\"bad_tone_nodes_with_generated_messages_chat_gpt_3_5_turbo.csv\")\n",
    "df_only_bad_tone[\"neg branch path\"] = df_only_bad_tone[\"neg branch path\"].apply(eval) # converts the list string into list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>node_id</th>\n",
       "      <th>tree_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>parent</th>\n",
       "      <th>Aggressive</th>\n",
       "      <th>AgreeBut</th>\n",
       "      <th>AgreeToDisagree</th>\n",
       "      <th>...</th>\n",
       "      <th>RephraseAttack</th>\n",
       "      <th>RequestClarification</th>\n",
       "      <th>Ridicule</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Softening</th>\n",
       "      <th>Sources</th>\n",
       "      <th>ViableTransformation</th>\n",
       "      <th>WQualifiers</th>\n",
       "      <th>neg branch path</th>\n",
       "      <th>generated_moderation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>d5307dl</td>\n",
       "      <td>4rl42j</td>\n",
       "      <td>1467909986</td>\n",
       "      <td>Hq3473</td>\n",
       "      <td>So a marginal increase in safety (say 1% less ...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[34, 33, 32, 31, 29, 28]</td>\n",
       "      <td>Hq3473, please remember to keep the discussion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>d533sdz</td>\n",
       "      <td>4rl42j</td>\n",
       "      <td>1467914340</td>\n",
       "      <td>Hq3473</td>\n",
       "      <td>I though bodily autonomy was absolute?</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[38, 37, 36, 35, 34, 33, 32, 31, 29, 28]</td>\n",
       "      <td>It seems like the discussion is getting into a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>d539o5o</td>\n",
       "      <td>4rl42j</td>\n",
       "      <td>1467921339</td>\n",
       "      <td>ThatBelligerentSloth</td>\n",
       "      <td>&lt;quote&gt;Again, why would even a marginal increa...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 3...</td>\n",
       "      <td>ThatBelligerentSloth, it's important to rememb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>d539xnf</td>\n",
       "      <td>4rl42j</td>\n",
       "      <td>1467921636</td>\n",
       "      <td>Hq3473</td>\n",
       "      <td>&lt;quote&gt;Because of bodily autonomy&lt;/quote&gt; Righ...</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 3...</td>\n",
       "      <td>Hq3473, it seems like you are engaging in a th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>d52epx2</td>\n",
       "      <td>4rl42j</td>\n",
       "      <td>1467864800</td>\n",
       "      <td>Slagernicus</td>\n",
       "      <td>I have a feeling that most people who have gon...</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[56, 55, 49, 48, 28]</td>\n",
       "      <td>Slagernicus, it's important to note that the t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>10540</td>\n",
       "      <td>dugl4q0</td>\n",
       "      <td>7yf2le</td>\n",
       "      <td>1518989877</td>\n",
       "      <td>icyMG</td>\n",
       "      <td>Education is useless they teach us outdated us...</td>\n",
       "      <td>10508</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[10540, 10508]</td>\n",
       "      <td>icyMG, while it's understandable that you may ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>10542</td>\n",
       "      <td>duh97vv</td>\n",
       "      <td>7yf2le</td>\n",
       "      <td>1519019073</td>\n",
       "      <td>icyMG</td>\n",
       "      <td>Yeah well the government doesn't really give a...</td>\n",
       "      <td>10541</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[10542, 10541, 10540, 10508]</td>\n",
       "      <td>icyMG, please remember to keep the conversatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>10551</td>\n",
       "      <td>duhtqls</td>\n",
       "      <td>7yf2le</td>\n",
       "      <td>1519056308</td>\n",
       "      <td>_busch</td>\n",
       "      <td>wait. so every teacher, in every school, in ev...</td>\n",
       "      <td>10550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[10551, 10550, 10508]</td>\n",
       "      <td>_busch, it's important to remember that the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>10555</td>\n",
       "      <td>duibhx7</td>\n",
       "      <td>7yf2le</td>\n",
       "      <td>1519073875</td>\n",
       "      <td>_busch</td>\n",
       "      <td>you should teach!</td>\n",
       "      <td>10554</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[10555, 10554, 10553, 10552, 10551, 10550, 10508]</td>\n",
       "      <td>_busch, please remember to keep the conversati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>10557</td>\n",
       "      <td>dui4q3s</td>\n",
       "      <td>7yf2le</td>\n",
       "      <td>1519067247</td>\n",
       "      <td>Mdcastle</td>\n",
       "      <td>Ted Bundy had an IQ of 136. Would more educati...</td>\n",
       "      <td>10508</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[10557, 10508]</td>\n",
       "      <td>Mdcastle, your point about Ted Bundy's IQ rais...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1732 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  node_id tree_id   timestamp                author  \\\n",
       "0        34  d5307dl  4rl42j  1467909986                Hq3473   \n",
       "1        38  d533sdz  4rl42j  1467914340                Hq3473   \n",
       "2        43  d539o5o  4rl42j  1467921339  ThatBelligerentSloth   \n",
       "3        44  d539xnf  4rl42j  1467921636                Hq3473   \n",
       "4        56  d52epx2  4rl42j  1467864800           Slagernicus   \n",
       "...     ...      ...     ...         ...                   ...   \n",
       "1727  10540  dugl4q0  7yf2le  1518989877                 icyMG   \n",
       "1728  10542  duh97vv  7yf2le  1519019073                 icyMG   \n",
       "1729  10551  duhtqls  7yf2le  1519056308                _busch   \n",
       "1730  10555  duibhx7  7yf2le  1519073875                _busch   \n",
       "1731  10557  dui4q3s  7yf2le  1519067247              Mdcastle   \n",
       "\n",
       "                                                   text  parent  Aggressive  \\\n",
       "0     So a marginal increase in safety (say 1% less ...      33           0   \n",
       "1                I though bodily autonomy was absolute?      37           0   \n",
       "2     <quote>Again, why would even a marginal increa...      42           0   \n",
       "3     <quote>Because of bodily autonomy</quote> Righ...      43           0   \n",
       "4     I have a feeling that most people who have gon...      55           0   \n",
       "...                                                 ...     ...         ...   \n",
       "1727  Education is useless they teach us outdated us...   10508           1   \n",
       "1728  Yeah well the government doesn't really give a...   10541           1   \n",
       "1729  wait. so every teacher, in every school, in ev...   10550           0   \n",
       "1730                                  you should teach!   10554           0   \n",
       "1731  Ted Bundy had an IQ of 136. Would more educati...   10508           0   \n",
       "\n",
       "      AgreeBut  AgreeToDisagree  ...  RephraseAttack  RequestClarification  \\\n",
       "0            0                0  ...               0                     0   \n",
       "1            0                0  ...               0                     0   \n",
       "2            0                0  ...               0                     0   \n",
       "3            0                0  ...               0                     0   \n",
       "4            0                0  ...               0                     0   \n",
       "...        ...              ...  ...             ...                   ...   \n",
       "1727         0                0  ...               0                     0   \n",
       "1728         0                0  ...               0                     0   \n",
       "1729         0                0  ...               0                     0   \n",
       "1730         0                0  ...               0                     0   \n",
       "1731         0                0  ...               0                     0   \n",
       "\n",
       "      Ridicule  Sarcasm  Softening  Sources  ViableTransformation  \\\n",
       "0            1        0          0        0                     0   \n",
       "1            0        1          0        0                     0   \n",
       "2            0        0          0        0                     0   \n",
       "3            0        0          1        0                     0   \n",
       "4            0        1          0        0                     0   \n",
       "...        ...      ...        ...      ...                   ...   \n",
       "1727         0        0          0        0                     0   \n",
       "1728         0        0          0        0                     0   \n",
       "1729         0        1          0        0                     0   \n",
       "1730         0        1          0        0                     0   \n",
       "1731         1        0          0        0                     0   \n",
       "\n",
       "      WQualifiers                                    neg branch path  \\\n",
       "0               0                           [34, 33, 32, 31, 29, 28]   \n",
       "1               0           [38, 37, 36, 35, 34, 33, 32, 31, 29, 28]   \n",
       "2               0  [43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 3...   \n",
       "3               0  [44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 3...   \n",
       "4               0                               [56, 55, 49, 48, 28]   \n",
       "...           ...                                                ...   \n",
       "1727            0                                     [10540, 10508]   \n",
       "1728            0                       [10542, 10541, 10540, 10508]   \n",
       "1729            0                              [10551, 10550, 10508]   \n",
       "1730            0  [10555, 10554, 10553, 10552, 10551, 10550, 10508]   \n",
       "1731            0                                     [10557, 10508]   \n",
       "\n",
       "                                   generated_moderation  \n",
       "0     Hq3473, please remember to keep the discussion...  \n",
       "1     It seems like the discussion is getting into a...  \n",
       "2     ThatBelligerentSloth, it's important to rememb...  \n",
       "3     Hq3473, it seems like you are engaging in a th...  \n",
       "4     Slagernicus, it's important to note that the t...  \n",
       "...                                                 ...  \n",
       "1727  icyMG, while it's understandable that you may ...  \n",
       "1728  icyMG, please remember to keep the conversatio...  \n",
       "1729  _busch, it's important to remember that the co...  \n",
       "1730  _busch, please remember to keep the conversati...  \n",
       "1731  Mdcastle, your point about Ted Bundy's IQ rais...  \n",
       "\n",
       "[1732 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_only_bad_tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tables\n",
    "pseudo_positive_df = utilities.obtain_pseudo_positive_conversation(conversation_df)\n",
    "pseudo_positive_df[\"generated_moderation\"] = \"No moderation note is required.\"\n",
    "pseudo_positive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16478/1056847176.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pseudo_positive_df[\"pseudo positive\"] = 1\n"
     ]
    }
   ],
   "source": [
    "pseudo_positive_df[\"pseudo positive\"] = 1\n",
    "df_only_bad_tone[\"pseudo positive\"] = 0\n",
    "df_only_bad_tone = df_only_bad_tone.rename({\"neg branch path\": \"branch_path\"}, axis=1)\n",
    "pseudo_positive_df = pseudo_positive_df.rename({\"pseudo positive branch path\": \"branch_path\"}, axis=1)\n",
    "# sample 1500 pseudo positive messages and concat to\n",
    "pseudo_positive_samples_df = pseudo_positive_df.sample(1500, random_state=1)\n",
    "\n",
    "train_and_test_df = pd.concat([df_only_bad_tone, pseudo_positive_samples_df]) # we will suffule them next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>node_id</th>\n",
       "      <th>tree_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>parent</th>\n",
       "      <th>Aggressive</th>\n",
       "      <th>AgreeBut</th>\n",
       "      <th>AgreeToDisagree</th>\n",
       "      <th>...</th>\n",
       "      <th>RequestClarification</th>\n",
       "      <th>Ridicule</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Softening</th>\n",
       "      <th>Sources</th>\n",
       "      <th>ViableTransformation</th>\n",
       "      <th>WQualifiers</th>\n",
       "      <th>branch_path</th>\n",
       "      <th>generated_moderation</th>\n",
       "      <th>pseudo positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>d5307dl</td>\n",
       "      <td>4rl42j</td>\n",
       "      <td>1467909986</td>\n",
       "      <td>Hq3473</td>\n",
       "      <td>So a marginal increase in safety (say 1% less ...</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[34, 33, 32, 31, 29, 28]</td>\n",
       "      <td>Hq3473, please remember to keep the discussion...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>d533sdz</td>\n",
       "      <td>4rl42j</td>\n",
       "      <td>1467914340</td>\n",
       "      <td>Hq3473</td>\n",
       "      <td>I though bodily autonomy was absolute?</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[38, 37, 36, 35, 34, 33, 32, 31, 29, 28]</td>\n",
       "      <td>It seems like the discussion is getting into a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>43</td>\n",
       "      <td>d539o5o</td>\n",
       "      <td>4rl42j</td>\n",
       "      <td>1467921339</td>\n",
       "      <td>ThatBelligerentSloth</td>\n",
       "      <td>&lt;quote&gt;Again, why would even a marginal increa...</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 3...</td>\n",
       "      <td>ThatBelligerentSloth, it's important to rememb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>d539xnf</td>\n",
       "      <td>4rl42j</td>\n",
       "      <td>1467921636</td>\n",
       "      <td>Hq3473</td>\n",
       "      <td>&lt;quote&gt;Because of bodily autonomy&lt;/quote&gt; Righ...</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 3...</td>\n",
       "      <td>Hq3473, it seems like you are engaging in a th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>d52epx2</td>\n",
       "      <td>4rl42j</td>\n",
       "      <td>1467864800</td>\n",
       "      <td>Slagernicus</td>\n",
       "      <td>I have a feeling that most people who have gon...</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[56, 55, 49, 48, 28]</td>\n",
       "      <td>Slagernicus, it's important to note that the t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>2500</td>\n",
       "      <td>dg3l7j7</td>\n",
       "      <td>64ki01</td>\n",
       "      <td>1491872193</td>\n",
       "      <td>potato1</td>\n",
       "      <td>Then all media are government endorsed.</td>\n",
       "      <td>2499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2500, 2499, 2498, 2492, 2490, 2489, 2488, 248...</td>\n",
       "      <td>No moderation note is required.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3940</th>\n",
       "      <td>3940</td>\n",
       "      <td>djfkxhx</td>\n",
       "      <td>6jmube</td>\n",
       "      <td>1498507572</td>\n",
       "      <td>Ansuz07</td>\n",
       "      <td>LGBT is not a federally protected class.</td>\n",
       "      <td>3939</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[3940, 3939, 3938, 3765]</td>\n",
       "      <td>No moderation note is required.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>4986</td>\n",
       "      <td>dkbe1xi</td>\n",
       "      <td>6nmn0d</td>\n",
       "      <td>1500257560</td>\n",
       "      <td>prettyinpinkpanther1</td>\n",
       "      <td>Im an advocate for American world supremacy ba...</td>\n",
       "      <td>4985</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[4986, 4985, 4915]</td>\n",
       "      <td>No moderation note is required.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10092</th>\n",
       "      <td>10092</td>\n",
       "      <td>dt6hj49</td>\n",
       "      <td>7snmsg</td>\n",
       "      <td>1516820989</td>\n",
       "      <td>OFGhost</td>\n",
       "      <td>What someone labels them has no impact on what...</td>\n",
       "      <td>10091</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[10092, 10091, 10084, 10083, 10082, 10081, 100...</td>\n",
       "      <td>No moderation note is required.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10462</th>\n",
       "      <td>10462</td>\n",
       "      <td>dtg4w2a</td>\n",
       "      <td>7txrjb</td>\n",
       "      <td>1517283382</td>\n",
       "      <td>MrEctomy</td>\n",
       "      <td>The problem is, you can't prove for a fact tha...</td>\n",
       "      <td>10419</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[10462, 10419]</td>\n",
       "      <td>No moderation note is required.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3232 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  node_id tree_id   timestamp                author  \\\n",
       "0         34  d5307dl  4rl42j  1467909986                Hq3473   \n",
       "1         38  d533sdz  4rl42j  1467914340                Hq3473   \n",
       "2         43  d539o5o  4rl42j  1467921339  ThatBelligerentSloth   \n",
       "3         44  d539xnf  4rl42j  1467921636                Hq3473   \n",
       "4         56  d52epx2  4rl42j  1467864800           Slagernicus   \n",
       "...      ...      ...     ...         ...                   ...   \n",
       "2500    2500  dg3l7j7  64ki01  1491872193               potato1   \n",
       "3940    3940  djfkxhx  6jmube  1498507572               Ansuz07   \n",
       "4986    4986  dkbe1xi  6nmn0d  1500257560  prettyinpinkpanther1   \n",
       "10092  10092  dt6hj49  7snmsg  1516820989               OFGhost   \n",
       "10462  10462  dtg4w2a  7txrjb  1517283382              MrEctomy   \n",
       "\n",
       "                                                    text  parent  Aggressive  \\\n",
       "0      So a marginal increase in safety (say 1% less ...      33           0   \n",
       "1                 I though bodily autonomy was absolute?      37           0   \n",
       "2      <quote>Again, why would even a marginal increa...      42           0   \n",
       "3      <quote>Because of bodily autonomy</quote> Righ...      43           0   \n",
       "4      I have a feeling that most people who have gon...      55           0   \n",
       "...                                                  ...     ...         ...   \n",
       "2500             Then all media are government endorsed.    2499           0   \n",
       "3940            LGBT is not a federally protected class.    3939           0   \n",
       "4986   Im an advocate for American world supremacy ba...    4985           0   \n",
       "10092  What someone labels them has no impact on what...   10091           0   \n",
       "10462  The problem is, you can't prove for a fact tha...   10419           0   \n",
       "\n",
       "       AgreeBut  AgreeToDisagree  ...  RequestClarification  Ridicule  \\\n",
       "0             0                0  ...                     0         1   \n",
       "1             0                0  ...                     0         0   \n",
       "2             0                0  ...                     0         0   \n",
       "3             0                0  ...                     0         0   \n",
       "4             0                0  ...                     0         0   \n",
       "...         ...              ...  ...                   ...       ...   \n",
       "2500          0                0  ...                     0         0   \n",
       "3940          0                0  ...                     0         0   \n",
       "4986          0                0  ...                     0         0   \n",
       "10092         0                0  ...                     0         0   \n",
       "10462         0                0  ...                     0         0   \n",
       "\n",
       "       Sarcasm  Softening  Sources  ViableTransformation  WQualifiers  \\\n",
       "0            0          0        0                     0            0   \n",
       "1            1          0        0                     0            0   \n",
       "2            0          0        0                     0            0   \n",
       "3            0          1        0                     0            0   \n",
       "4            1          0        0                     0            0   \n",
       "...        ...        ...      ...                   ...          ...   \n",
       "2500         0          0        0                     0            0   \n",
       "3940         0          0        0                     0            0   \n",
       "4986         0          0        0                     0            0   \n",
       "10092        0          0        0                     0            0   \n",
       "10462        0          0        0                     0            0   \n",
       "\n",
       "                                             branch_path  \\\n",
       "0                               [34, 33, 32, 31, 29, 28]   \n",
       "1               [38, 37, 36, 35, 34, 33, 32, 31, 29, 28]   \n",
       "2      [43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 33, 3...   \n",
       "3      [44, 43, 42, 41, 40, 39, 38, 37, 36, 35, 34, 3...   \n",
       "4                                   [56, 55, 49, 48, 28]   \n",
       "...                                                  ...   \n",
       "2500   [2500, 2499, 2498, 2492, 2490, 2489, 2488, 248...   \n",
       "3940                            [3940, 3939, 3938, 3765]   \n",
       "4986                                  [4986, 4985, 4915]   \n",
       "10092  [10092, 10091, 10084, 10083, 10082, 10081, 100...   \n",
       "10462                                     [10462, 10419]   \n",
       "\n",
       "                                    generated_moderation  pseudo positive  \n",
       "0      Hq3473, please remember to keep the discussion...                0  \n",
       "1      It seems like the discussion is getting into a...                0  \n",
       "2      ThatBelligerentSloth, it's important to rememb...                0  \n",
       "3      Hq3473, it seems like you are engaging in a th...                0  \n",
       "4      Slagernicus, it's important to note that the t...                0  \n",
       "...                                                  ...              ...  \n",
       "2500                     No moderation note is required.                1  \n",
       "3940                     No moderation note is required.                1  \n",
       "4986                     No moderation note is required.                1  \n",
       "10092                    No moderation note is required.                1  \n",
       "10462                    No moderation note is required.                1  \n",
       "\n",
       "[3232 rows x 41 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate train dataset\n",
    "train_data = list()\n",
    "for i in range(train_and_test_df.shape[0]):\n",
    "    index = train_and_test_df[\"index\"].iloc[i]\n",
    "    pseudo_positive_label = train_and_test_df[\"pseudo positive\"].iloc[i]\n",
    "    prompt = utilities.generate_branch_for_negative_tone_prompt_for_mistral(train_and_test_df, conversation_df, node_index=i, branch_col_name=\"branch_path\")\n",
    "    label = train_and_test_df[\"generated_moderation\"].iloc[i]\n",
    "    train_data.append((index, prompt, label, pseudo_positive_label))\n",
    "\n",
    "dataset_df = pd.DataFrame(train_data, columns=[\"index\", 'prompt', 'label', \"pseudo positive\"])\n",
    "dataset_df.to_pickle(\"train_dataset_include_pseudo_positive.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.018593311309814453,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Generating train split",
       "rate": null,
       "total": 0,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "964a7a0813d0429a9dd6b3399971c985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['index', 'prompt', 'label', 'pseudo positive'],\n",
       "    num_rows: 3232\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "mod_dataset = load_dataset(\"pandas\", data_files=\"train_dataset_include_pseudo_positive.pkl\", split='train')\n",
    "mod_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012959480285644531,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 3232,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1122993df024455d99ef72861a36ca6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3232 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_mod_prompt(data_point):\n",
    "    return f\"\"\"{data_point['prompt']}\\n{data_point['label']}</s>\"\"\"\n",
    "\n",
    "\n",
    "text_column = [generate_mod_prompt(ex) for ex in mod_dataset]\n",
    "mod_dataset = mod_dataset.add_column(\"full_prompt\", text_column)\n",
    "\n",
    "mod_dataset = mod_dataset.shuffle(seed=1234)  # Shuffle dataset here\n",
    "mod_dataset = mod_dataset.map(lambda samples: tokenizer(samples[\"full_prompt\"]), batched=True)\n",
    "mod_dataset = mod_dataset.train_test_split(test_size=0.2, seed=1234)\n",
    "train_data = mod_dataset[\"train\"]\n",
    "test_data = mod_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['index', 'prompt', 'label', 'pseudo positive', 'full_prompt', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 2585\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['index', 'prompt', 'label', 'pseudo positive', 'full_prompt', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 647\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v_proj', 'gate_proj', 'q_proj', 'o_proj', 'up_proj', 'down_proj', 'k_proj']\n"
     ]
    }
   ],
   "source": [
    "import bitsandbytes as bnb\n",
    "def find_all_linear_names(model):\n",
    "  cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)\n",
    "  lora_module_names = set()\n",
    "  for name, module in model.named_modules():\n",
    "    if isinstance(module, cls):\n",
    "      names = name.split('.')\n",
    "      lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n",
    "    if 'lm_head' in lora_module_names: # needed for 16-bit\n",
    "      lora_module_names.remove('lm_head')\n",
    "  return list(lora_module_names)\n",
    "\n",
    "modules = find_all_linear_names(model)\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    target_modules=modules,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable: 20971520 | total: 7262703616 | Percentage: 0.2888%\n"
     ]
    }
   ],
   "source": [
    "trainable, total = model.get_nb_trainable_parameters()\n",
    "print(f\"Trainable: {trainable} | total: {total} | Percentage: {trainable/total*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:225: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01329946517944336,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 2585,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9989cc656e9b4d048fc055b04bdfc8bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2585 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012995243072509766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Map",
       "rate": null,
       "total": 647,
       "unit": " examples",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "713d352dd21e4e32be4186e9f2fd7a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/647 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/trl/trainer/sft_trainer.py:294: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/.local/lib/python3.9/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n",
      "Detected kernel version 4.14.287, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "#new code using SFTTrainer\n",
    "import transformers\n",
    "\n",
    "from trl import SFTTrainer\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    "    dataset_text_field=\"full_prompt\",\n",
    "    peft_config=lora_config,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=2,\n",
    "        gradient_accumulation_steps=4,\n",
    "        warmup_steps=1,\n",
    "        max_steps=100,\n",
    "        learning_rate=2.5e-5,\n",
    "        logging_steps=1,\n",
    "        save_steps=10,\n",
    "        save_strategy=\"steps\",\n",
    "        eval_steps=10,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        do_eval=True,\n",
    "        output_dir=\"outputs_mine_include_pseudo_positive\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        bf16=True,\n",
    "        \n",
    "        logging_dir=\"./logs_mine\"\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 1:11:30, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.074500</td>\n",
       "      <td>2.026882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.023900</td>\n",
       "      <td>1.891220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.856100</td>\n",
       "      <td>1.810342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.668800</td>\n",
       "      <td>1.771670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.831500</td>\n",
       "      <td>1.744970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.947400</td>\n",
       "      <td>1.724498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.807800</td>\n",
       "      <td>1.706986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.646300</td>\n",
       "      <td>1.694251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.833700</td>\n",
       "      <td>1.686669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.658100</td>\n",
       "      <td>1.683793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/.local/lib/python3.9/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=1.8404169750213624, metrics={'train_runtime': 4305.2209, 'train_samples_per_second': 0.186, 'train_steps_per_second': 0.023, 'total_flos': 3.48009359597568e+16, 'train_loss': 1.8404169750213624, 'epoch': 0.31})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load fined tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012901544570922852,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51fefc4a2aee4ecba65dfec6f897cf0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id,  # Mistral, same as before\n",
    "    quantization_config=bnb_config,  # Same quantization config as before\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "ft_model = PeftModel.from_pretrained(base_model, \"outputs_mine_include_pseudo_positive/checkpoint-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model, tokenizer):\n",
    "    model_inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False).to(\"cuda\")\n",
    "\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=300, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "    decoded = tokenizer.batch_decode(generated_ids)\n",
    "    \n",
    "    return decoded[0]\n",
    "\n",
    "def get_mod_message_generation_function(model, tokenizer):\n",
    "    def generate_moderation_message(row):\n",
    "        print('sample:', row.name)\n",
    "        answer = get_completion(row['prompt'], model=model, tokenizer=tokenizer)\n",
    "        splits = answer.split('[/INST]')\n",
    "        if len(splits) != 2:\n",
    "            return 'model produced illegal output..'\n",
    "        return splits[-1].rstrip('</s>')\n",
    "    \n",
    "    return generate_moderation_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_data.to_pandas(), test_data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: 1\n",
      "sample: 2\n",
      "sample: 3\n",
      "sample: 4\n",
      "sample: 5\n",
      "sample: 6\n",
      "sample: 7\n",
      "sample: 8\n",
      "sample: 9\n",
      "sample: 10\n",
      "sample: 11\n",
      "sample: 12\n",
      "sample: 13\n",
      "sample: 14\n",
      "sample: 15\n",
      "sample: 16\n",
      "sample: 17\n",
      "sample: 18\n",
      "sample: 19\n",
      "sample: 20\n",
      "sample: 21\n",
      "sample: 22\n",
      "sample: 23\n",
      "sample: 24\n",
      "sample: 25\n",
      "sample: 26\n",
      "sample: 27\n",
      "sample: 28\n",
      "sample: 29\n",
      "sample: 30\n",
      "sample: 31\n",
      "sample: 32\n",
      "sample: 33\n",
      "sample: 34\n",
      "sample: 35\n",
      "sample: 36\n",
      "sample: 37\n",
      "sample: 38\n",
      "sample: 39\n",
      "sample: 40\n",
      "sample: 41\n",
      "sample: 42\n",
      "sample: 43\n",
      "sample: 44\n",
      "sample: 45\n",
      "sample: 46\n",
      "sample: 47\n",
      "sample: 48\n",
      "sample: 49\n",
      "sample: 50\n",
      "sample: 51\n",
      "sample: 52\n",
      "sample: 53\n",
      "sample: 54\n",
      "sample: 55\n",
      "sample: 56\n",
      "sample: 57\n",
      "sample: 58\n",
      "sample: 59\n",
      "sample: 60\n",
      "sample: 61\n",
      "sample: 62\n",
      "sample: 63\n",
      "sample: 64\n",
      "sample: 65\n",
      "sample: 66\n",
      "sample: 67\n",
      "sample: 68\n",
      "sample: 69\n",
      "sample: 70\n",
      "sample: 71\n",
      "sample: 72\n",
      "sample: 73\n",
      "sample: 74\n",
      "sample: 75\n",
      "sample: 76\n",
      "sample: 77\n",
      "sample: 78\n",
      "sample: 79\n",
      "sample: 80\n",
      "sample: 81\n",
      "sample: 82\n",
      "sample: 83\n",
      "sample: 84\n",
      "sample: 85\n",
      "sample: 86\n",
      "sample: 87\n",
      "sample: 88\n",
      "sample: 89\n",
      "sample: 90\n",
      "sample: 91\n",
      "sample: 92\n",
      "sample: 93\n",
      "sample: 94\n",
      "sample: 95\n",
      "sample: 96\n",
      "sample: 97\n",
      "sample: 98\n",
      "sample: 99\n",
      "sample: 100\n",
      "sample: 101\n",
      "sample: 102\n",
      "sample: 103\n",
      "sample: 104\n",
      "sample: 105\n",
      "sample: 106\n",
      "sample: 107\n",
      "sample: 108\n",
      "sample: 109\n",
      "sample: 110\n",
      "sample: 111\n",
      "sample: 112\n",
      "sample: 113\n",
      "sample: 114\n",
      "sample: 115\n",
      "sample: 116\n",
      "sample: 117\n",
      "sample: 118\n",
      "sample: 119\n",
      "sample: 120\n",
      "sample: 121\n",
      "sample: 122\n",
      "sample: 123\n",
      "sample: 124\n",
      "sample: 125\n",
      "sample: 126\n",
      "sample: 127\n",
      "sample: 128\n",
      "sample: 129\n",
      "sample: 130\n",
      "sample: 131\n",
      "sample: 132\n",
      "sample: 133\n",
      "sample: 134\n",
      "sample: 135\n",
      "sample: 136\n",
      "sample: 137\n",
      "sample: 138\n",
      "sample: 139\n",
      "sample: 140\n",
      "sample: 141\n",
      "sample: 142\n",
      "sample: 143\n",
      "sample: 144\n",
      "sample: 145\n",
      "sample: 146\n",
      "sample: 147\n",
      "sample: 148\n",
      "sample: 149\n",
      "sample: 150\n",
      "sample: 151\n",
      "sample: 152\n",
      "sample: 153\n",
      "sample: 154\n",
      "sample: 155\n",
      "sample: 156\n",
      "sample: 157\n",
      "sample: 158\n",
      "sample: 159\n",
      "sample: 160\n",
      "sample: 161\n",
      "sample: 162\n",
      "sample: 163\n",
      "sample: 164\n",
      "sample: 165\n",
      "sample: 166\n",
      "sample: 167\n",
      "sample: 168\n",
      "sample: 169\n",
      "sample: 170\n",
      "sample: 171\n",
      "sample: 172\n",
      "sample: 173\n",
      "sample: 174\n",
      "sample: 175\n",
      "sample: 176\n",
      "sample: 177\n",
      "sample: 178\n",
      "sample: 179\n",
      "sample: 180\n",
      "sample: 181\n",
      "sample: 182\n",
      "sample: 183\n",
      "sample: 184\n",
      "sample: 185\n",
      "sample: 186\n",
      "sample: 187\n",
      "sample: 188\n",
      "sample: 189\n",
      "sample: 190\n",
      "sample: 191\n",
      "sample: 192\n",
      "sample: 193\n",
      "sample: 194\n",
      "sample: 195\n",
      "sample: 196\n",
      "sample: 197\n",
      "sample: 198\n",
      "sample: 199\n",
      "sample: 200\n",
      "sample: 201\n",
      "sample: 202\n",
      "sample: 203\n",
      "sample: 204\n",
      "sample: 205\n",
      "sample: 206\n",
      "sample: 207\n",
      "sample: 208\n",
      "sample: 209\n",
      "sample: 210\n",
      "sample: 211\n",
      "sample: 212\n",
      "sample: 213\n",
      "sample: 214\n",
      "sample: 215\n",
      "sample: 216\n",
      "sample: 217\n",
      "sample: 218\n",
      "sample: 219\n",
      "sample: 220\n",
      "sample: 221\n",
      "sample: 222\n",
      "sample: 223\n",
      "sample: 224\n",
      "sample: 225\n",
      "sample: 226\n",
      "sample: 227\n",
      "sample: 228\n",
      "sample: 229\n",
      "sample: 230\n",
      "sample: 231\n",
      "sample: 232\n",
      "sample: 233\n",
      "sample: 234\n",
      "sample: 235\n",
      "sample: 236\n",
      "sample: 237\n",
      "sample: 238\n",
      "sample: 239\n",
      "sample: 240\n",
      "sample: 241\n",
      "sample: 242\n",
      "sample: 243\n",
      "sample: 244\n",
      "sample: 245\n",
      "sample: 246\n",
      "sample: 247\n",
      "sample: 248\n",
      "sample: 249\n",
      "sample: 250\n",
      "sample: 251\n",
      "sample: 252\n",
      "sample: 253\n",
      "sample: 254\n",
      "sample: 255\n",
      "sample: 256\n",
      "sample: 257\n",
      "sample: 258\n",
      "sample: 259\n",
      "sample: 260\n",
      "sample: 261\n",
      "sample: 262\n",
      "sample: 263\n",
      "sample: 264\n",
      "sample: 265\n",
      "sample: 266\n",
      "sample: 267\n",
      "sample: 268\n",
      "sample: 269\n",
      "sample: 270\n",
      "sample: 271\n",
      "sample: 272\n",
      "sample: 273\n",
      "sample: 274\n",
      "sample: 275\n",
      "sample: 276\n",
      "sample: 277\n",
      "sample: 278\n",
      "sample: 279\n",
      "sample: 280\n",
      "sample: 281\n",
      "sample: 282\n",
      "sample: 283\n",
      "sample: 284\n",
      "sample: 285\n",
      "sample: 286\n",
      "sample: 287\n",
      "sample: 288\n",
      "sample: 289\n",
      "sample: 290\n",
      "sample: 291\n",
      "sample: 292\n",
      "sample: 293\n",
      "sample: 294\n",
      "sample: 295\n",
      "sample: 296\n",
      "sample: 297\n",
      "sample: 298\n",
      "sample: 299\n",
      "sample: 300\n",
      "sample: 301\n",
      "sample: 302\n",
      "sample: 303\n",
      "sample: 304\n",
      "sample: 305\n",
      "sample: 306\n",
      "sample: 307\n",
      "sample: 308\n",
      "sample: 309\n",
      "sample: 310\n",
      "sample: 311\n",
      "sample: 312\n",
      "sample: 313\n",
      "sample: 314\n",
      "sample: 315\n",
      "sample: 316\n",
      "sample: 317\n",
      "sample: 318\n",
      "sample: 319\n",
      "sample: 320\n",
      "sample: 321\n",
      "sample: 322\n",
      "sample: 323\n",
      "sample: 324\n",
      "sample: 325\n",
      "sample: 326\n",
      "sample: 327\n",
      "sample: 328\n",
      "sample: 329\n",
      "sample: 330\n",
      "sample: 331\n",
      "sample: 332\n",
      "sample: 333\n",
      "sample: 334\n",
      "sample: 335\n",
      "sample: 336\n",
      "sample: 337\n",
      "sample: 338\n",
      "sample: 339\n",
      "sample: 340\n",
      "sample: 341\n",
      "sample: 342\n",
      "sample: 343\n",
      "sample: 344\n",
      "sample: 345\n",
      "sample: 346\n",
      "sample: 347\n",
      "sample: 348\n",
      "sample: 349\n",
      "sample: 350\n",
      "sample: 351\n",
      "sample: 352\n",
      "sample: 353\n",
      "sample: 354\n",
      "sample: 355\n",
      "sample: 356\n",
      "sample: 357\n",
      "sample: 358\n",
      "sample: 359\n",
      "sample: 360\n",
      "sample: 361\n",
      "sample: 362\n",
      "sample: 363\n",
      "sample: 364\n",
      "sample: 365\n",
      "sample: 366\n",
      "sample: 367\n",
      "sample: 368\n",
      "sample: 369\n",
      "sample: 370\n",
      "sample: 371\n",
      "sample: 372\n",
      "sample: 373\n",
      "sample: 374\n",
      "sample: 375\n",
      "sample: 376\n",
      "sample: 377\n",
      "sample: 378\n",
      "sample: 379\n",
      "sample: 380\n",
      "sample: 381\n",
      "sample: 382\n",
      "sample: 383\n",
      "sample: 384\n",
      "sample: 385\n",
      "sample: 386\n",
      "sample: 387\n",
      "sample: 388\n",
      "sample: 389\n",
      "sample: 390\n",
      "sample: 391\n",
      "sample: 392\n",
      "sample: 393\n",
      "sample: 394\n",
      "sample: 395\n",
      "sample: 396\n",
      "sample: 397\n",
      "sample: 398\n",
      "sample: 399\n",
      "sample: 400\n",
      "sample: 401\n",
      "sample: 402\n",
      "sample: 403\n",
      "sample: 404\n",
      "sample: 405\n",
      "sample: 406\n",
      "sample: 407\n",
      "sample: 408\n",
      "sample: 409\n",
      "sample: 410\n",
      "sample: 411\n",
      "sample: 412\n",
      "sample: 413\n",
      "sample: 414\n",
      "sample: 415\n",
      "sample: 416\n",
      "sample: 417\n",
      "sample: 418\n",
      "sample: 419\n",
      "sample: 420\n",
      "sample: 421\n",
      "sample: 422\n",
      "sample: 423\n",
      "sample: 424\n",
      "sample: 425\n",
      "sample: 426\n",
      "sample: 427\n",
      "sample: 428\n",
      "sample: 429\n",
      "sample: 430\n",
      "sample: 431\n",
      "sample: 432\n",
      "sample: 433\n",
      "sample: 434\n",
      "sample: 435\n",
      "sample: 436\n",
      "sample: 437\n",
      "sample: 438\n",
      "sample: 439\n",
      "sample: 440\n",
      "sample: 441\n",
      "sample: 442\n",
      "sample: 443\n",
      "sample: 444\n",
      "sample: 445\n",
      "sample: 446\n",
      "sample: 447\n",
      "sample: 448\n",
      "sample: 449\n",
      "sample: 450\n",
      "sample: 451\n",
      "sample: 452\n",
      "sample: 453\n",
      "sample: 454\n",
      "sample: 455\n",
      "sample: 456\n",
      "sample: 457\n",
      "sample: 458\n",
      "sample: 459\n",
      "sample: 460\n",
      "sample: 461\n",
      "sample: 462\n",
      "sample: 463\n",
      "sample: 464\n",
      "sample: 465\n",
      "sample: 466\n",
      "sample: 467\n",
      "sample: 468\n",
      "sample: 469\n",
      "sample: 470\n",
      "sample: 471\n",
      "sample: 472\n",
      "sample: 473\n",
      "sample: 474\n",
      "sample: 475\n",
      "sample: 476\n",
      "sample: 477\n",
      "sample: 478\n",
      "sample: 479\n",
      "sample: 480\n",
      "sample: 481\n",
      "sample: 482\n",
      "sample: 483\n",
      "sample: 484\n",
      "sample: 485\n",
      "sample: 486\n",
      "sample: 487\n",
      "sample: 488\n",
      "sample: 489\n",
      "sample: 490\n",
      "sample: 491\n",
      "sample: 492\n",
      "sample: 493\n",
      "sample: 494\n",
      "sample: 495\n",
      "sample: 496\n",
      "sample: 497\n",
      "sample: 498\n",
      "sample: 499\n",
      "sample: 500\n",
      "sample: 501\n",
      "sample: 502\n",
      "sample: 503\n",
      "sample: 504\n",
      "sample: 505\n",
      "sample: 506\n",
      "sample: 507\n",
      "sample: 508\n",
      "sample: 509\n",
      "sample: 510\n",
      "sample: 511\n",
      "sample: 512\n",
      "sample: 513\n",
      "sample: 514\n",
      "sample: 515\n",
      "sample: 516\n",
      "sample: 517\n",
      "sample: 518\n",
      "sample: 519\n",
      "sample: 520\n",
      "sample: 521\n",
      "sample: 522\n",
      "sample: 523\n",
      "sample: 524\n",
      "sample: 525\n",
      "sample: 526\n",
      "sample: 527\n",
      "sample: 528\n",
      "sample: 529\n",
      "sample: 530\n",
      "sample: 531\n",
      "sample: 532\n",
      "sample: 533\n",
      "sample: 534\n",
      "sample: 535\n",
      "sample: 536\n",
      "sample: 537\n",
      "sample: 538\n",
      "sample: 539\n",
      "sample: 540\n",
      "sample: 541\n",
      "sample: 542\n",
      "sample: 543\n",
      "sample: 544\n",
      "sample: 545\n",
      "sample: 546\n",
      "sample: 547\n",
      "sample: 548\n",
      "sample: 549\n",
      "sample: 550\n",
      "sample: 551\n",
      "sample: 552\n",
      "sample: 553\n",
      "sample: 554\n",
      "sample: 555\n",
      "sample: 556\n",
      "sample: 557\n",
      "sample: 558\n",
      "sample: 559\n",
      "sample: 560\n",
      "sample: 561\n",
      "sample: 562\n",
      "sample: 563\n",
      "sample: 564\n",
      "sample: 565\n",
      "sample: 566\n",
      "sample: 567\n",
      "sample: 568\n",
      "sample: 569\n",
      "sample: 570\n",
      "sample: 571\n",
      "sample: 572\n",
      "sample: 573\n",
      "sample: 574\n",
      "sample: 575\n",
      "sample: 576\n",
      "sample: 577\n",
      "sample: 578\n",
      "sample: 579\n",
      "sample: 580\n",
      "sample: 581\n",
      "sample: 582\n",
      "sample: 583\n",
      "sample: 584\n",
      "sample: 585\n",
      "sample: 586\n",
      "sample: 587\n",
      "sample: 588\n",
      "sample: 589\n",
      "sample: 590\n",
      "sample: 591\n",
      "sample: 592\n",
      "sample: 593\n",
      "sample: 594\n",
      "sample: 595\n",
      "sample: 596\n",
      "sample: 597\n",
      "sample: 598\n",
      "sample: 599\n",
      "sample: 600\n",
      "sample: 601\n",
      "sample: 602\n",
      "sample: 603\n",
      "sample: 604\n",
      "sample: 605\n",
      "sample: 606\n",
      "sample: 607\n",
      "sample: 608\n",
      "sample: 609\n",
      "sample: 610\n",
      "sample: 611\n",
      "sample: 612\n",
      "sample: 613\n",
      "sample: 614\n",
      "sample: 615\n",
      "sample: 616\n",
      "sample: 617\n",
      "sample: 618\n",
      "sample: 619\n",
      "sample: 620\n",
      "sample: 621\n",
      "sample: 622\n",
      "sample: 623\n",
      "sample: 624\n",
      "sample: 625\n",
      "sample: 626\n",
      "sample: 627\n",
      "sample: 628\n",
      "sample: 629\n",
      "sample: 630\n",
      "sample: 631\n",
      "sample: 632\n",
      "sample: 633\n",
      "sample: 634\n",
      "sample: 635\n",
      "sample: 636\n",
      "sample: 637\n",
      "sample: 638\n",
      "sample: 639\n",
      "sample: 640\n",
      "sample: 641\n",
      "sample: 642\n",
      "sample: 643\n",
      "sample: 644\n",
      "sample: 645\n",
      "sample: 646\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model_moderation = get_mod_message_generation_function(ft_model, eval_tokenizer)\n",
    "test_df['fine_tuned_model_moderation'] = test_df.apply(fine_tuned_model_moderation, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01293802261352539,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 3,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9c7a0a860f4451ab43cfbcd220df96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: 0\n",
      "sample: 1\n",
      "sample: 2\n",
      "sample: 3\n",
      "sample: 4\n",
      "sample: 5\n",
      "sample: 6\n",
      "sample: 7\n",
      "sample: 8\n",
      "sample: 9\n",
      "sample: 10\n",
      "sample: 11\n",
      "sample: 12\n",
      "sample: 13\n",
      "sample: 14\n",
      "sample: 15\n",
      "sample: 16\n",
      "sample: 17\n",
      "sample: 18\n",
      "sample: 19\n",
      "sample: 20\n",
      "sample: 21\n",
      "sample: 22\n",
      "sample: 23\n",
      "sample: 24\n",
      "sample: 25\n",
      "sample: 26\n",
      "sample: 27\n",
      "sample: 28\n",
      "sample: 29\n",
      "sample: 30\n",
      "sample: 31\n",
      "sample: 32\n",
      "sample: 33\n",
      "sample: 34\n",
      "sample: 35\n",
      "sample: 36\n",
      "sample: 37\n",
      "sample: 38\n",
      "sample: 39\n",
      "sample: 40\n",
      "sample: 41\n",
      "sample: 42\n",
      "sample: 43\n",
      "sample: 44\n",
      "sample: 45\n",
      "sample: 46\n",
      "sample: 47\n",
      "sample: 48\n",
      "sample: 49\n",
      "sample: 50\n",
      "sample: 51\n",
      "sample: 52\n",
      "sample: 53\n",
      "sample: 54\n",
      "sample: 55\n",
      "sample: 56\n",
      "sample: 57\n",
      "sample: 58\n",
      "sample: 59\n",
      "sample: 60\n",
      "sample: 61\n",
      "sample: 62\n",
      "sample: 63\n",
      "sample: 64\n",
      "sample: 65\n",
      "sample: 66\n",
      "sample: 67\n",
      "sample: 68\n",
      "sample: 69\n",
      "sample: 70\n",
      "sample: 71\n",
      "sample: 72\n",
      "sample: 73\n",
      "sample: 74\n",
      "sample: 75\n",
      "sample: 76\n",
      "sample: 77\n",
      "sample: 78\n",
      "sample: 79\n",
      "sample: 80\n",
      "sample: 81\n",
      "sample: 82\n",
      "sample: 83\n",
      "sample: 84\n",
      "sample: 85\n",
      "sample: 86\n",
      "sample: 87\n",
      "sample: 88\n",
      "sample: 89\n",
      "sample: 90\n",
      "sample: 91\n",
      "sample: 92\n",
      "sample: 93\n",
      "sample: 94\n",
      "sample: 95\n",
      "sample: 96\n",
      "sample: 97\n",
      "sample: 98\n",
      "sample: 99\n",
      "sample: 100\n",
      "sample: 101\n",
      "sample: 102\n",
      "sample: 103\n",
      "sample: 104\n",
      "sample: 105\n",
      "sample: 106\n",
      "sample: 107\n",
      "sample: 108\n",
      "sample: 109\n",
      "sample: 110\n",
      "sample: 111\n",
      "sample: 112\n",
      "sample: 113\n",
      "sample: 114\n",
      "sample: 115\n",
      "sample: 116\n",
      "sample: 117\n",
      "sample: 118\n",
      "sample: 119\n",
      "sample: 120\n",
      "sample: 121\n",
      "sample: 122\n",
      "sample: 123\n",
      "sample: 124\n",
      "sample: 125\n",
      "sample: 126\n",
      "sample: 127\n",
      "sample: 128\n",
      "sample: 129\n",
      "sample: 130\n",
      "sample: 131\n",
      "sample: 132\n",
      "sample: 133\n",
      "sample: 134\n",
      "sample: 135\n",
      "sample: 136\n",
      "sample: 137\n",
      "sample: 138\n",
      "sample: 139\n",
      "sample: 140\n",
      "sample: 141\n",
      "sample: 142\n",
      "sample: 143\n",
      "sample: 144\n",
      "sample: 145\n",
      "sample: 146\n",
      "sample: 147\n",
      "sample: 148\n",
      "sample: 149\n",
      "sample: 150\n",
      "sample: 151\n",
      "sample: 152\n",
      "sample: 153\n",
      "sample: 154\n",
      "sample: 155\n",
      "sample: 156\n",
      "sample: 157\n",
      "sample: 158\n",
      "sample: 159\n",
      "sample: 160\n",
      "sample: 161\n",
      "sample: 162\n",
      "sample: 163\n",
      "sample: 164\n",
      "sample: 165\n",
      "sample: 166\n",
      "sample: 167\n",
      "sample: 168\n",
      "sample: 169\n",
      "sample: 170\n",
      "sample: 171\n",
      "sample: 172\n",
      "sample: 173\n",
      "sample: 174\n",
      "sample: 175\n",
      "sample: 176\n",
      "sample: 177\n",
      "sample: 178\n",
      "sample: 179\n",
      "sample: 180\n",
      "sample: 181\n",
      "sample: 182\n",
      "sample: 183\n",
      "sample: 184\n",
      "sample: 185\n",
      "sample: 186\n",
      "sample: 187\n",
      "sample: 188\n",
      "sample: 189\n",
      "sample: 190\n",
      "sample: 191\n",
      "sample: 192\n",
      "sample: 193\n",
      "sample: 194\n",
      "sample: 195\n",
      "sample: 196\n",
      "sample: 197\n",
      "sample: 198\n",
      "sample: 199\n",
      "sample: 200\n",
      "sample: 201\n",
      "sample: 202\n",
      "sample: 203\n",
      "sample: 204\n",
      "sample: 205\n",
      "sample: 206\n",
      "sample: 207\n",
      "sample: 208\n",
      "sample: 209\n",
      "sample: 210\n",
      "sample: 211\n",
      "sample: 212\n",
      "sample: 213\n",
      "sample: 214\n",
      "sample: 215\n",
      "sample: 216\n",
      "sample: 217\n",
      "sample: 218\n",
      "sample: 219\n",
      "sample: 220\n",
      "sample: 221\n",
      "sample: 222\n",
      "sample: 223\n",
      "sample: 224\n",
      "sample: 225\n",
      "sample: 226\n",
      "sample: 227\n",
      "sample: 228\n",
      "sample: 229\n",
      "sample: 230\n",
      "sample: 231\n",
      "sample: 232\n",
      "sample: 233\n",
      "sample: 234\n",
      "sample: 235\n",
      "sample: 236\n",
      "sample: 237\n",
      "sample: 238\n",
      "sample: 239\n",
      "sample: 240\n",
      "sample: 241\n",
      "sample: 242\n",
      "sample: 243\n",
      "sample: 244\n",
      "sample: 245\n",
      "sample: 246\n",
      "sample: 247\n",
      "sample: 248\n",
      "sample: 249\n",
      "sample: 250\n",
      "sample: 251\n",
      "sample: 252\n",
      "sample: 253\n",
      "sample: 254\n",
      "sample: 255\n",
      "sample: 256\n",
      "sample: 257\n",
      "sample: 258\n",
      "sample: 259\n",
      "sample: 260\n",
      "sample: 261\n",
      "sample: 262\n",
      "sample: 263\n",
      "sample: 264\n",
      "sample: 265\n",
      "sample: 266\n",
      "sample: 267\n",
      "sample: 268\n",
      "sample: 269\n",
      "sample: 270\n",
      "sample: 271\n",
      "sample: 272\n",
      "sample: 273\n",
      "sample: 274\n",
      "sample: 275\n",
      "sample: 276\n",
      "sample: 277\n",
      "sample: 278\n",
      "sample: 279\n",
      "sample: 280\n",
      "sample: 281\n",
      "sample: 282\n",
      "sample: 283\n",
      "sample: 284\n",
      "sample: 285\n",
      "sample: 286\n",
      "sample: 287\n",
      "sample: 288\n",
      "sample: 289\n",
      "sample: 290\n",
      "sample: 291\n",
      "sample: 292\n",
      "sample: 293\n",
      "sample: 294\n",
      "sample: 295\n",
      "sample: 296\n",
      "sample: 297\n",
      "sample: 298\n",
      "sample: 299\n",
      "sample: 300\n",
      "sample: 301\n",
      "sample: 302\n",
      "sample: 303\n",
      "sample: 304\n",
      "sample: 305\n",
      "sample: 306\n",
      "sample: 307\n",
      "sample: 308\n",
      "sample: 309\n",
      "sample: 310\n",
      "sample: 311\n",
      "sample: 312\n",
      "sample: 313\n",
      "sample: 314\n",
      "sample: 315\n",
      "sample: 316\n",
      "sample: 317\n",
      "sample: 318\n",
      "sample: 319\n",
      "sample: 320\n",
      "sample: 321\n",
      "sample: 322\n",
      "sample: 323\n",
      "sample: 324\n",
      "sample: 325\n",
      "sample: 326\n",
      "sample: 327\n",
      "sample: 328\n",
      "sample: 329\n",
      "sample: 330\n",
      "sample: 331\n",
      "sample: 332\n",
      "sample: 333\n",
      "sample: 334\n",
      "sample: 335\n",
      "sample: 336\n",
      "sample: 337\n",
      "sample: 338\n",
      "sample: 339\n",
      "sample: 340\n",
      "sample: 341\n",
      "sample: 342\n",
      "sample: 343\n",
      "sample: 344\n",
      "sample: 345\n",
      "sample: 346\n",
      "sample: 347\n",
      "sample: 348\n",
      "sample: 349\n",
      "sample: 350\n",
      "sample: 351\n",
      "sample: 352\n",
      "sample: 353\n",
      "sample: 354\n",
      "sample: 355\n",
      "sample: 356\n",
      "sample: 357\n",
      "sample: 358\n",
      "sample: 359\n",
      "sample: 360\n",
      "sample: 361\n",
      "sample: 362\n",
      "sample: 363\n",
      "sample: 364\n",
      "sample: 365\n",
      "sample: 366\n",
      "sample: 367\n",
      "sample: 368\n",
      "sample: 369\n",
      "sample: 370\n",
      "sample: 371\n",
      "sample: 372\n",
      "sample: 373\n",
      "sample: 374\n",
      "sample: 375\n",
      "sample: 376\n",
      "sample: 377\n",
      "sample: 378\n",
      "sample: 379\n",
      "sample: 380\n",
      "sample: 381\n",
      "sample: 382\n",
      "sample: 383\n",
      "sample: 384\n",
      "sample: 385\n",
      "sample: 386\n",
      "sample: 387\n",
      "sample: 388\n",
      "sample: 389\n",
      "sample: 390\n",
      "sample: 391\n",
      "sample: 392\n",
      "sample: 393\n",
      "sample: 394\n",
      "sample: 395\n",
      "sample: 396\n",
      "sample: 397\n",
      "sample: 398\n",
      "sample: 399\n",
      "sample: 400\n",
      "sample: 401\n",
      "sample: 402\n",
      "sample: 403\n",
      "sample: 404\n",
      "sample: 405\n",
      "sample: 406\n",
      "sample: 407\n",
      "sample: 408\n",
      "sample: 409\n",
      "sample: 410\n",
      "sample: 411\n",
      "sample: 412\n",
      "sample: 413\n",
      "sample: 414\n",
      "sample: 415\n",
      "sample: 416\n",
      "sample: 417\n",
      "sample: 418\n",
      "sample: 419\n",
      "sample: 420\n",
      "sample: 421\n",
      "sample: 422\n",
      "sample: 423\n",
      "sample: 424\n",
      "sample: 425\n",
      "sample: 426\n",
      "sample: 427\n",
      "sample: 428\n",
      "sample: 429\n",
      "sample: 430\n",
      "sample: 431\n",
      "sample: 432\n",
      "sample: 433\n",
      "sample: 434\n",
      "sample: 435\n",
      "sample: 436\n",
      "sample: 437\n",
      "sample: 438\n",
      "sample: 439\n",
      "sample: 440\n",
      "sample: 441\n",
      "sample: 442\n",
      "sample: 443\n",
      "sample: 444\n",
      "sample: 445\n",
      "sample: 446\n",
      "sample: 447\n",
      "sample: 448\n",
      "sample: 449\n",
      "sample: 450\n",
      "sample: 451\n",
      "sample: 452\n",
      "sample: 453\n",
      "sample: 454\n",
      "sample: 455\n",
      "sample: 456\n",
      "sample: 457\n",
      "sample: 458\n",
      "sample: 459\n",
      "sample: 460\n",
      "sample: 461\n",
      "sample: 462\n",
      "sample: 463\n",
      "sample: 464\n",
      "sample: 465\n",
      "sample: 466\n",
      "sample: 467\n",
      "sample: 468\n",
      "sample: 469\n",
      "sample: 470\n",
      "sample: 471\n",
      "sample: 472\n",
      "sample: 473\n",
      "sample: 474\n",
      "sample: 475\n",
      "sample: 476\n",
      "sample: 477\n",
      "sample: 478\n",
      "sample: 479\n",
      "sample: 480\n",
      "sample: 481\n",
      "sample: 482\n",
      "sample: 483\n",
      "sample: 484\n",
      "sample: 485\n",
      "sample: 486\n",
      "sample: 487\n",
      "sample: 488\n",
      "sample: 489\n",
      "sample: 490\n",
      "sample: 491\n",
      "sample: 492\n",
      "sample: 493\n",
      "sample: 494\n",
      "sample: 495\n",
      "sample: 496\n",
      "sample: 497\n",
      "sample: 498\n",
      "sample: 499\n",
      "sample: 500\n",
      "sample: 501\n",
      "sample: 502\n",
      "sample: 503\n",
      "sample: 504\n",
      "sample: 505\n",
      "sample: 506\n",
      "sample: 507\n",
      "sample: 508\n",
      "sample: 509\n",
      "sample: 510\n",
      "sample: 511\n",
      "sample: 512\n",
      "sample: 513\n",
      "sample: 514\n",
      "sample: 515\n",
      "sample: 516\n",
      "sample: 517\n",
      "sample: 518\n",
      "sample: 519\n",
      "sample: 520\n",
      "sample: 521\n",
      "sample: 522\n",
      "sample: 523\n",
      "sample: 524\n",
      "sample: 525\n",
      "sample: 526\n",
      "sample: 527\n",
      "sample: 528\n",
      "sample: 529\n",
      "sample: 530\n",
      "sample: 531\n",
      "sample: 532\n",
      "sample: 533\n",
      "sample: 534\n",
      "sample: 535\n",
      "sample: 536\n",
      "sample: 537\n",
      "sample: 538\n",
      "sample: 539\n",
      "sample: 540\n",
      "sample: 541\n",
      "sample: 542\n",
      "sample: 543\n",
      "sample: 544\n",
      "sample: 545\n",
      "sample: 546\n",
      "sample: 547\n",
      "sample: 548\n",
      "sample: 549\n",
      "sample: 550\n",
      "sample: 551\n",
      "sample: 552\n",
      "sample: 553\n",
      "sample: 554\n",
      "sample: 555\n",
      "sample: 556\n",
      "sample: 557\n",
      "sample: 558\n",
      "sample: 559\n",
      "sample: 560\n",
      "sample: 561\n",
      "sample: 562\n",
      "sample: 563\n",
      "sample: 564\n",
      "sample: 565\n",
      "sample: 566\n",
      "sample: 567\n",
      "sample: 568\n",
      "sample: 569\n",
      "sample: 570\n",
      "sample: 571\n",
      "sample: 572\n",
      "sample: 573\n",
      "sample: 574\n",
      "sample: 575\n",
      "sample: 576\n",
      "sample: 577\n",
      "sample: 578\n",
      "sample: 579\n",
      "sample: 580\n",
      "sample: 581\n",
      "sample: 582\n",
      "sample: 583\n",
      "sample: 584\n",
      "sample: 585\n",
      "sample: 586\n",
      "sample: 587\n",
      "sample: 588\n",
      "sample: 589\n",
      "sample: 590\n",
      "sample: 591\n",
      "sample: 592\n",
      "sample: 593\n",
      "sample: 594\n",
      "sample: 595\n",
      "sample: 596\n",
      "sample: 597\n",
      "sample: 598\n",
      "sample: 599\n",
      "sample: 600\n",
      "sample: 601\n",
      "sample: 602\n",
      "sample: 603\n",
      "sample: 604\n",
      "sample: 605\n",
      "sample: 606\n",
      "sample: 607\n",
      "sample: 608\n",
      "sample: 609\n",
      "sample: 610\n",
      "sample: 611\n",
      "sample: 612\n",
      "sample: 613\n",
      "sample: 614\n",
      "sample: 615\n",
      "sample: 616\n",
      "sample: 617\n",
      "sample: 618\n",
      "sample: 619\n",
      "sample: 620\n",
      "sample: 621\n",
      "sample: 622\n",
      "sample: 623\n",
      "sample: 624\n",
      "sample: 625\n",
      "sample: 626\n",
      "sample: 627\n",
      "sample: 628\n",
      "sample: 629\n",
      "sample: 630\n",
      "sample: 631\n",
      "sample: 632\n",
      "sample: 633\n",
      "sample: 634\n",
      "sample: 635\n",
      "sample: 636\n",
      "sample: 637\n",
      "sample: 638\n",
      "sample: 639\n",
      "sample: 640\n",
      "sample: 641\n",
      "sample: 642\n",
      "sample: 643\n",
      "sample: 644\n",
      "sample: 645\n",
      "sample: 646\n"
     ]
    }
   ],
   "source": [
    "base_model_generation = get_mod_message_generation_function(model, tokenizer)\n",
    "test_df['base_model_moderation'] = test_df.apply(base_model_generation, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[[\"index\", \"pseudo positive\", \"prompt\", \"label\", \"base_model_moderation\", \"fine_tuned_model_moderation\"]]\n",
    "test_df.to_csv(\"test_with_fine_tuned_moderations_mine_include_pseudo_positive.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
